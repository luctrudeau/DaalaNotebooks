{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A Pragmatic Introduction to Perceptual Vector Quantization (part 1)\n",
    "###Luc Trudeau\n",
    "\n",
    "## Context\n",
    "This guide explains Perceptual Vector Quantization by presenting it in a practical context. By pratical, I mean that we will implement the Perceptual Vector Quantization in python right here in this notebook. The intended audience is mainly programmers, not necessarily python programmers, and the idea is that you can leverage your programming skills to better understand Perceptual Vector Quantization.\n",
    "\n",
    "Our objective for this first part is to \"_perceptually vector quantize_\" the following vector **v**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "v = array([1,3,3,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What does it even mean to \"_vector quantize_\" something?\n",
    "\n",
    "Let's start with quantization. Here's an example of quantization:\n",
    "![](images/quantization.png)\n",
    "In this example, an image with 96615 colors is quantized to 64 colors. The python code of this quantization example is available [here](http://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html).\n",
    "\n",
    "Vector quantization is a fancy way of saying that we want to convert the whole vector into a single code. This code is called a codeword. The idea is that all the codewords are defined in a codebook. Before we present the codebook, let's start with the concepts of gain and shape, which will be needed to better understand how codewords work.\n",
    "\n",
    "## Gain and Shape\n",
    "To \"_perceptually vector quantize_\" **v**, we must first compute the norm of **v**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm (aka gain) of v = 8.246211\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt\n",
    "from numpy import dot\n",
    "\n",
    "def gain(v):\n",
    "    return sqrt(dot(v,v))\n",
    "print(\"Norm (aka gain) of v = %f\" % (gain(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you noticed, we refer to the norm of **v** as the gain of **v**, which represents the amount of energy in the **v** (_I know there's a norm function in numpy, but doing it this way shows you why the gain measures energy_).\n",
    "\n",
    "The next thing we need is the unit vector of **v**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit vector (aka shape): [ 0.12126781  0.36380344  0.36380344  0.84887469]\n"
     ]
    }
   ],
   "source": [
    "from numpy import divide\n",
    "\n",
    "def shape(v):\n",
    "    return divide(v, gain(v))\n",
    "print(\"Unit vector (aka shape): %s\" % (shape(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer to the unit vector of **v** as the shape of **v**. As its name suggest, the values of this vector show the shape of the energy distribution of **v**. The **shape** vector is in the same direction as **v** but is squaled to unit length. \n",
    "\n",
    "We can get back **v** from **shape** like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v = [ 1.  3.  3.  7.]\n"
     ]
    }
   ],
   "source": [
    "print(\"v = %s\" % (shape(v) * gain(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of \"_perceptually vector quantizing_\" **v**, we will \"_perceptually vector quantize_\" **shape** and \"_scalar quantize_\" **gain**.\n",
    "\n",
    ">Wait a second, this requires \"_perceptually vector quantizing_\" 4 values, plus \"_scalar quantizing_\" the gain. How is this better than just \"_perceptually vector quantizing_\" the 4 values of **v**? \n",
    "\n",
    "![](images/consider.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain of v2 = 16.4924225025\n",
      "Shape of v2 = [ 0.12126781  0.36380344  0.36380344  0.84887469]\n"
     ]
    }
   ],
   "source": [
    "v2 = [2,6,6,14]\n",
    "print(\"Gain of v2 = %s\" % (gain(v2)))\n",
    "print(\"Shape of v2 = %s\" % (shape(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(shape(v).all() == shape(v2).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the shape of the **v** instead of the **v** itself, all vectors with the same shape will have the same codeword. Vectors with the same shape, are vectors that point in the same direction. In other words all different scales of the same vector. There's more to it than that, but for now let's focus on building the codebook.\n",
    "\n",
    "## Building the codebook\n",
    "You might have imagined the codebook as a big book of codes, each code cherry picked by an engineer for optimal performance. This is not that type of codebook, basically a simple equation is used to generate all possible values. The equation is: The sum of absolute values of the codeword must sum to **k**.\n",
    "\n",
    "Just for fun (because we **won't** need it later) let's build the codebook. This is probably not the fastest way to build the codebook, but it should be easy to understand. We have 4 nested loops because we have 4 elements in **v**. Since the absolute value operator is used, valid values range from -**k** to **k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2, 0, 0, 0\n",
      "-1, -1, 0, 0\n",
      "-1, 0, -1, 0\n",
      "-1, 0, 0, -1\n",
      "-1, 0, 0, 1\n",
      "-1, 0, 1, 0\n",
      "-1, 1, 0, 0\n",
      "0, -2, 0, 0\n",
      "0, -1, -1, 0\n",
      "0, -1, 0, -1\n",
      "0, -1, 0, 1\n",
      "0, -1, 1, 0\n",
      "0, 0, -2, 0\n",
      "0, 0, -1, -1\n",
      "0, 0, -1, 1\n",
      "0, 0, 0, -2\n",
      "0, 0, 0, 2\n",
      "0, 0, 1, -1\n",
      "0, 0, 1, 1\n",
      "0, 0, 2, 0\n",
      "0, 1, -1, 0\n",
      "0, 1, 0, -1\n",
      "0, 1, 0, 1\n",
      "0, 1, 1, 0\n",
      "0, 2, 0, 0\n",
      "1, -1, 0, 0\n",
      "1, 0, -1, 0\n",
      "1, 0, 0, -1\n",
      "1, 0, 0, 1\n",
      "1, 0, 1, 0\n",
      "1, 1, 0, 0\n",
      "2, 0, 0, 0\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "codebook = [] \n",
    "\n",
    "for x0 in range(-k,k+1):\n",
    "    for x1 in range(-k,k+1):\n",
    "        for x2 in range(-k,k+1):\n",
    "            for x3 in range(-k,k+1):\n",
    "                if abs(x0) + abs(x1) + abs(x2) + abs(x3) == k:\n",
    "                    codebook.append([x0, x1, x2, x3])\n",
    "                    print(\"%d, %d, %d, %d\" % (x0, x1, x2, x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorry about that, but that's not the right codebook, it's the codebook for **v**. Like we said before, instead of using **v** we are using the shape of **v**. The codebook for the shape of **v** contains the normalized versions of the previous codewords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  0.  0.]\n",
      "[-0.70710678 -0.70710678  0.          0.        ]\n",
      "[-0.70710678  0.         -0.70710678  0.        ]\n",
      "[-0.70710678  0.          0.         -0.70710678]\n",
      "[-0.70710678  0.          0.          0.70710678]\n",
      "[-0.70710678  0.          0.70710678  0.        ]\n",
      "[-0.70710678  0.70710678  0.          0.        ]\n",
      "[ 0. -1.  0.  0.]\n",
      "[ 0.         -0.70710678 -0.70710678  0.        ]\n",
      "[ 0.         -0.70710678  0.         -0.70710678]\n",
      "[ 0.         -0.70710678  0.          0.70710678]\n",
      "[ 0.         -0.70710678  0.70710678  0.        ]\n",
      "[ 0.  0. -1.  0.]\n",
      "[ 0.          0.         -0.70710678 -0.70710678]\n",
      "[ 0.          0.         -0.70710678  0.70710678]\n",
      "[ 0.  0.  0. -1.]\n",
      "[ 0.  0.  0.  1.]\n",
      "[ 0.          0.          0.70710678 -0.70710678]\n",
      "[ 0.          0.          0.70710678  0.70710678]\n",
      "[ 0.  0.  1.  0.]\n",
      "[ 0.          0.70710678 -0.70710678  0.        ]\n",
      "[ 0.          0.70710678  0.         -0.70710678]\n",
      "[ 0.          0.70710678  0.          0.70710678]\n",
      "[ 0.          0.70710678  0.70710678  0.        ]\n",
      "[ 0.  1.  0.  0.]\n",
      "[ 0.70710678 -0.70710678  0.          0.        ]\n",
      "[ 0.70710678  0.         -0.70710678  0.        ]\n",
      "[ 0.70710678  0.          0.         -0.70710678]\n",
      "[ 0.70710678  0.          0.          0.70710678]\n",
      "[ 0.70710678  0.          0.70710678  0.        ]\n",
      "[ 0.70710678  0.70710678  0.          0.        ]\n",
      "[ 1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for codeword in codebook:\n",
    "    codebook[i] = shape(codeword)\n",
    "    print(codebook[i])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The parameter k\n",
    "\n",
    "> What's **k** again?\n",
    "\n",
    "The parameter **k** is the value that the absolute values of the elements of the codeword must sum to in order to be part of the codebook. A higher value for **k** will generate a much bigger codebook (_try it out, change the value of k to 5 instead of 2_).\n",
    "\n",
    "> Are more codewords better?\n",
    "\n",
    "Well you don't want too few codewords because you won't have enough precision, and too many codewords will lead to wasted processing, so you need just enough codewords. It just so happens that the gain is a good indicator of \"_just enough codewords_\".\n",
    "\n",
    "##Finding the code\n",
    "\n",
    "> Aren't we suppose to \"_vector quantize_\" something at some point?\n",
    "\n",
    "Almost there, we just need to specify a value for **k**. The \"_vector quantize_\" value of **v** depends on **k**. For this example, let's continue with **k** = 2.\n",
    "\n",
    "A nice feature of our codebook is **that we don't need it** (best feature ever). We know the rule: the sum of the absolute values of the elements of the codeword must be equal to **k**. We don't need the codebook, all we can do is to find the smallest change to **v** so that sum of the absolute value of its elemens is **k**.\n",
    "\n",
    "One (not very efficient, but easy to understand) way of doing this is to spread **k** over the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptual Vector Quantization of v = [ 0.          0.          0.4472136   0.89442719] \n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from numpy import sign\n",
    "from numpy import copy\n",
    "from numpy import round\n",
    "import sys\n",
    "\n",
    "def findCode(v, k):\n",
    "    _shape = shape(v)\n",
    "\n",
    "    # Here we spread k of the shape. Without rounding it sums to k, but the elements of the codeword must be integers\n",
    "    codeword = round(_shape/sum(abs(_shape))*k)\n",
    "    sa = sum(abs(codeword))\n",
    "    \n",
    "    if sa != k:\n",
    "        step = sign(k - sa)\n",
    "        while sa != k:\n",
    "            minsse = sys.maxsize\n",
    "            for i in range(0,4): # Iteratively apply step to every element and keep the best.\n",
    "                codeword[i] = codeword[i] + step \n",
    "                sse = sum((_shape - shape(codeword))**2)\n",
    "            \n",
    "                if sse < minsse:\n",
    "                    bestI = i\n",
    "                    minsse = sse\n",
    "                    \n",
    "                codeword[i] = codeword[i] - step #Undo the step   \n",
    "            \n",
    "            codeword[bestI] = codeword[bestI] + step # Perform best step\n",
    "            sa = sa + step\n",
    "\n",
    "    return codeword\n",
    "        \n",
    "print(\"Perceptual Vector Quantization of v = %s \" % (shape(findCode(v,3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##We did it!\n",
    "we \"_perceptually vector quantized_\" **v**! You can check the codeword is in the codebook.\n",
    "\n",
    "The burning question now is: \"how good is our quantization of **v**?\". Let's find out: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed v = [ 0.          5.83095189  0.          5.83095189]\n",
      "Sum of Absolute Difference: 8.000000\n",
      "Sum of Squared Error: 19.380962\n"
     ]
    }
   ],
   "source": [
    "recon = shape(findCode(v,2)) * gain(v)\n",
    "print(\"Reconstructed v = %s\" % (recon))\n",
    "print(\"Sum of Absolute Difference: %f\" % (sum(abs(recon - v))))\n",
    "print(\"Sum of Squared Error: %f\" % (sum((recon - v)**2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! That's far from **v**.\n",
    "\n",
    "## Increasing k\n",
    "Let's see what happens when we increase **k**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed v = [ 0.          2.48632624  2.48632624  7.45897873]\n",
      "Sum of Absolute Difference: 2.486326\n",
      "Sum of Squared Error: 1.738383\n"
     ]
    }
   ],
   "source": [
    "recon = shape(findCode(v,5)) * gain(v)\n",
    "print(\"Reconstructed v = %s\" % (recon))\n",
    "print(\"Sum of Absolute Difference: %f\" % (sum(abs(recon - v))))\n",
    "print(\"Sum of Squared Error: %f\" % (sum((recon - v)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding more codes to our codebook, we decrease the error. Let's draw a plot to better understand what happens to the error when we increase k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          5.83095189  0.          5.83095189]\n",
      "[ 0.          0.          3.68781778  7.37563557]\n",
      "[ 0.          3.36650165  3.36650165  6.73300329]\n",
      "[ 0.          2.48632624  2.48632624  7.45897873]\n",
      "[ 2.38047614  2.38047614  2.38047614  7.14142843]\n",
      "[ 0.          3.59894164  1.79947082  7.19788329]\n",
      "[ 0.          3.36650165  3.36650165  6.73300329]\n",
      "[ 1.64924225  3.2984845   3.2984845   6.596969  ]\n",
      "[ 1.41421356  2.82842712  2.82842712  7.07106781]\n",
      "[ 1.22927259  2.45854519  2.45854519  7.37563557]\n",
      "[ 1.16619038  2.33238076  3.49857114  6.99714227]\n",
      "[ 1.1119189   3.33575669  3.33575669  6.67151339]\n",
      "[ 1.  3.  3.  7.]\n",
      "[ 0.90513928  2.71541783  2.71541783  7.24111421]\n",
      "[ 0.86922699  3.47690795  2.60768096  6.9538159 ]\n",
      "[ 0.8372759   3.34910359  3.34910359  6.69820718]\n",
      "[ 0.77232845  3.08931378  3.08931378  6.95095601]\n",
      "[ 0.7150372   2.86014879  2.86014879  7.15037199]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEPCAYAAABfmE8WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VdW9//H3IiFABkgYMjDIDIGQIIhM4jW1OAIKFlS8\nWrwq/qy1DvWKYwsitygqYq9WvZZanHBCrKgVp6aCIIMKJCQBGYVAEoYgBELG9ftjn4QEQsYzks/r\nec6TM+79TXLyOStrr72WsdYiIiKBq5mvCxARkcZRkIuIBDgFuYhIgFOQi4gEOAW5iEiAU5CLiAS4\nGoPcGNPFGPMvY8xGY0yaMeZO1/1tjTGfG2M2G2M+M8ZEeqdcERE5malpHLkxJhaItdauM8aEA98B\n44H/AvZba+cYY+4Hoqy1D3ilYhERqaLGFrm1Nttau851PR/IADoBVwALXE9bgBPuIiLiA3XuIzfG\ndAMGAauAGGttjuuhHCDG7ZWJiEid1CnIXd0qi4C7rLVHKj9mnb4ZnecvIuIjwbU9wRjTHCfEX7PW\nfuC6O8cYE2utzTbGxAG51bxO4S4i0gDWWlOf59c2asUA84F0a+28Sg99CExxXZ8CfHDya13F+N1l\n+vTpPq9BNammpliXaqrbpSFqa5GfB1wPbDDG/OC670HgceAdY8zNwA7g6gbtXUREGq3GILfWLuf0\nrfbR7i9HRETqq8md2ZmcnOzrEk6hmupGNdWdP9almjynxhOCGrVhY6ynti0icqYyxmDrebCz1lEr\njVFmy2hmmlyjX2rgHD+XcmrsiDt4NMi3HtxK73a9PbkLCUAKL4c+1MRdPNpc/iH7h9qfJNKEzZs3\nj5dfftnXZUiA82yQ71WQi9QkOjqao0eP+roMCXAeDfJ1Oes8uXkREUEtchGRgOfRIC8pK2Hvkb2e\n3IWIWy1fvpyRI0cSGRlJu3btGDVqFGvXrq14PD8/n/DwcC6//PJTXtutWzdCQ0Np3bo1UVFRnHfe\nebz00ks6uCse59EgPzv2bB3wlIBx+PBhxo4dy1133UVeXh5ZWVlMnz6dFi1aVDxn0aJFnHXWWaSk\npJCTk1Pl9cYYPvroIw4fPsxPP/3EAw88wBNPPMHNN9/s7W9FmhiPBvmg2EGsy1Y/uQSGzZs3Y4zh\nmmuuwRhDy5Ytueiii0hMTKx4zoIFC7jllls477zzeP3110+7rYiICMaNG8fbb7/NggUL2Lhxoze+\nBWmiPBvkcYPUIpeA0bdvX4KCgrjxxhv59NNPycvLq/L4zp07+frrr7n66qu5+uqrefXVV2vd5rnn\nnkvnzp1ZtmyZp8oW8ULXig54Sj0Z455LfUVERLB8+XKMMUydOpXo6GiuvPJKcnOd6fZfe+01hg4d\nSufOnbnqqqtIT09n3bra/+Ps2LHjKR8KIu7k0SDv264v2fnZHC487MndyBnGWvdcGiI+Pp5XXnmF\nXbt2kZaWxp49e7j77rsBePXVV5k0aRIA7dq1Izk5mQULFtS0OQCysrJo27ZtwwoSqQOPBnlQsyAG\nRA9gffZ6T+5GxCP69u3LlClTSEtLY+XKlWzZsoVZs2YRFxdHXFwcK1eu5M0336SsrOy021izZg1Z\nWVmMGjXKi5VLU+PxGa00ckUCxaZNm5g7dy5ZWVkA7Nq1i4ULFzJixAj+/ve/c/HFF5ORkcH69etZ\nv349aWlpFBQU8Mknn1Rso3yo4eHDh/noo4+YPHkyN9xwAwkJCT75nqRp8OikWeCMXFmVtcrTuxFp\ntIiICFatWsXcuXM5dOgQkZGRjBs3jjlz5tC1a1dee+01oqOjq7zmhhtu4NVXX2Xs2LEAjBs3juDg\nYJo1a0ZCQgL33nsvt912my++HWlCPB/kcYN48bsXPb0bkUbr2LEjb7/9drWPHTx4sNr7n3/++Yrr\n27dv90hdIrXxeNfKgOgBbNq/iaLSIk/vSkSkSfJ4kIc2D6V7VHfS96V7elciIk2SV5bvGRQ7SOPJ\nRUQ8xCtBrpErIiKe47UWueZcERHxDK+1yNfnrKfMnv7ECRERaRivBHm70Ha0adGGbXnbvLE7EZEm\nxStBDs54cnWviIi4n/eCXCNXREQ8wmtBrpErEghOt9RbUVER9957L126dCEiIoLu3btzzz33VLyu\nfJm3iIiIisudd97pw+9EmhKPn6JfTiNXxN+VL/X20ksvcfXVV1NYWMjy5ctp0aIFs2fP5vvvv2fN\nmjXExsZWLDJRrnyZtwsvvNCH34E0VV5rkZ/V5iyOlxwnJz+n9ieL+EB1S72NHj2axMRE1q5dy/jx\n44mNjQWga9eu3HDDDT6uWMThtSA3xqh7RfxaTUu9DR8+nLlz5/LCCy+QmppaMV1tZdXdJ+INXuta\ngRPdK5f2utSbu5UAYx5twDpt1bDT6xes5Uu9PfHEE0ydOpXs7Gwuv/xyXn75ZR588EGioqJ44403\nuOeee2jXrh2zZ8/m17/+tbMvaxk/fjzBwSf+pJ566iluvvlmt3wvIjUxnmpFGGPsydt+fcPrLNm8\nhLcnVj9VqJz5jDEB03LdtGkT119/Pb179+bNN9+suL+wsJD58+dz5513snHjRvr27Uv37t2ZP39+\nvfrIjTG88cYb5ObmViwnJ+L6G6lXa8ZrXSugxZglsFRe6q2yFi1acPvttxMVFUV6umb1FN/zapDH\nt48n60gWRwqPeHO3InVS01Jvzz77LP/+978pKCigpKSEBQsWkJ+fz6BBgypeHyj/aciZx6tBHtws\nmIQOCWzI2eDN3YrUSflSb8OGDSM8PJwRI0aQlJTEU089RWhoKPfeey9xcXF06NCBF154gUWLFtGt\nW7eK148bN67KOPJf/epXvvtmpEnxah85wK1LbiUpJok7ht7hkf2KfwukPnJPUx+5VMfv+8hBJwaJ\niLib94M8bpDGkouIuJHXgzwxOpGMfRkUlxZ7e9ciImckrwd5WEgYXSO7krE/w9u7FhE5I3k9yEFT\n2oqIuJNPglxzroiIuI9X51opNyh2EJ/8+Ikvdi1+wBj3zKUiIg6fBPnZsWezLnsd1lr9UTcx5WPI\n582bR3R0tI+rETkz+CTIO4R1IDwknO2HttMjqocvShAfCwsLIzc319dl+IWwsDBflyABzidBDicW\nY1aQN01Tp071dQkiZ4xaD3YaY/5mjMkxxqRWum+GMWa3MeYH16XeE4xr5IqIiHvUZdTKK8DJQW2B\nudbaQa7Lp/XdsUauiIi4R61Bbq1dBuRV81CjjlJqzhUREfdozDjy3xlj1htj5htjIuv74m6R3cgv\nymff0X2NKEFERBp6sPMFYKbr+mPA08ApixPOmDGj4npycjLJyckVtysvxnxxz4sbWIaISGBLSUkh\nJSWlUduo03zkxphuwBJrbWJdHzvdfOSV3fPpPcRFxDHtvGl1r1hE5AzmtfnIjTFxlW5OAFJP99ya\naEpbEZHGq8vww4XACqCvMWaXMeYm4AljzAZjzHrgAuCehuxcizGLiDSe15d6q6y4tJg2j7dh3337\nCAvR2W0iIgGx1FtlzYOa079Dfy3GLCLSCD4NctCJQSIijeXzINep+iIijeP7II8bxLocneEpItJQ\nPg/ypJgkNuZu1GLMIiIN5PMgDw8Jp0ubLmTuz/R1KSIiAcnnQQ6aQEtEpDH8Isg1ckVEpOH8IsgH\nxepUfRGRhvKLIK+8GLOIiNSPXwR5THgMrYJbsfPnnb4uRUQk4PhFkINrJkSdGCQiUm/+E+QauSIi\n0iB+E+QauSIi0jB+E+QauSIi0jB+E+Tdo7pzuPAw+4/t93UpIiIBxW+CvJlpxsCYgeonFxGpJ78J\nctCUtiIiDeFfQa4pbUVE6s2vglyLMYuI1J9fBXn/Dv3ZcWgHx4qP+boUEZGA4VdBHhIUQnz7eFJz\nUn1diohIwPCrIAedGCQiUl9+F+QauSIiUj/+F+QauSIiUi9+F+RJMUmk5aZRUlbi61JERAKC3wV5\n6xat6RjRkU37N/m6FBGRgOB3QQ6a0lZEpD78Msg1ckVEpO78Msg1pa2ISN35Z5DHDdJizCIideSX\nQR4bHktIUAi7Du/ydSkiIn7PL4McNIGWiEhd+W2Qa+SKiEjd+HWQ64CniEjt/DbINQRRRKRu/DbI\ne7btSV5BHgcLDvq6FBERv+a3Qd7MNGNgrBZjFhGpjd8GOcDZMRq5IiJSG78Ock1pKyJSO/8Oci0y\nISJSK78O8v4d+rM1bysFxQW+LkVExG/5dZC3CG5B33Z9SctN83UpIiJ+y6+DHJx+co0nFxE5Pb8P\nco1cERGpmd8HeVJMEqm5qb4uQ0TEb/l9kCfGJLIhZ4PmJhcROY1ag9wY8zdjTI4xJrXSfW2NMZ8b\nYzYbYz4zxkR6qsD2oe2JaBHBzp93emoXIiIBrS4t8leAS0+67wHgc2ttH+BL122PSYpJYkPOBk/u\nQkQkYNUa5NbaZUDeSXdfASxwXV8AjHdzXVUkRSvIRUROp6F95DHW2hzX9Rwgxk31VEstchGR0wtu\n7AastdYYU+2RyBkzZlRcT05OJjk5uUH7SIpJ4rGvH2vQa0VE/FlKSgopKSmN2oapy2gQY0w3YIm1\nNtF1OxNIttZmG2PigH9Za+NPeo1110iTotIi2jzehgPTDhDaPNQt2xQR8UfGGKy1pj6vaWjXyofA\nFNf1KcAHDdxOnYQEhdCnXR/S96V7cjciIgGpLsMPFwIrgL7GmF3GmP8CHgcuMsZsBi503fYo9ZOL\niFSv1j5ya+3k0zw02s211EgjV0REquf3Z3aWU4tcRKR6ARfkOlVfRKSqgAny2PBYjDHszd/r61JE\nRPxKwAS5MUbdKyIi1QiYIAcd8BQRqU5gBbla5CIip1CQi4gEuIAK8v4d+vPjwR8pKi3ydSkiIn4j\noIK8VfNWdIvsRub+TF+XIiLiNwIqyEHdKyIiJwu8INfIFRGRKgIvyNUiFxGpQkEuIhLgAi7Iz2pz\nFkeLj7Lv6D5flyIi4hcCLsjLT9VPzU31dSkiIn4h4IIcdMBTRKSywAxy9ZOLiFTwaJDv3++Z7SrI\nRURO8GiQz5jhme0OiB5A+r50SspKPLMDEZEA4tEgf+cdSPfAwvcRLSKIi4hjy8Et7t+4iEiA8WiQ\nP/QQ3HuvZ7at7hUREYdHg/z222HbNvj0U/dvWyNXREQcHg3ykBB46in4/e+hxM3d2WqRi4g4PD78\ncOxY6NgRXnrJvdtVkIuIODwe5MbA3Lkwcybk5blvuz2ierD/2H5+Pv6z+zYqIhKAvHJCUFISjB8P\ns2a5b5tBzYJIiE7Qqfoi0uR57czOmTNhwQL48Uf3bVMHPEVEvBjkMTFw333OxV3UTy4i4uW5Vu66\nCzZsgK++cs/2FOQiIl4O8pYtYc4cuOceKC1t/PYSYxJJzU2lzJY1fmMiIgHK67Mf/upX0KYNvPJK\n47fVtlVbIltGsuPQjsZvTEQkQHk9yI2BZ56BP/4Rjhxp/PbUvSIiTZ1P5iM/5xy4+GKYPbvx29LI\nFRFp6ny2sMSf/uSc7bljR+O2oxa5iDR1Pgvyjh2dUSz339+47SjIRaSp8+lSb//937ByJXzzTcO3\n0addH3Yd3sXRoqPuK0xEJID4NMhDQ51+8rvvhrIGjiBsHtSc+PbxbNy30b3FiYgECJ8vvjx5MjRr\nBm+80fBtqHtFRJoynwd5s2Ywb56zmtDRBvaOaOSKiDRlPg9ygBEjYNQoePLJhr1eLXIRacqMtdYz\nGzbG1mfbO3fC4MGwfj107ly/feXk59Dv+X4cmHYAY0w9KxUR8R/GGKy19Qoyv2iRA3TtCrfd5nSx\n1FdMeAzNg5qTdSTL/YWJiPg5vwlygAcegC++gNWr6/9ada+ISFPlV0EeEeGsIvT730N9e3x0wFNE\nmiq/CnKAKVOc0Svvvlu/16lFLiJNld8FeVCQMzvitGlw/HjdX6cgF5Gmyu+CHCA52RnB8swzdX9N\nvw792Jq3lcKSQo/VJSLijxoV5MaYHcaYDcaYH4wxDThEeXpz5sDTT0N2dt2e3zK4JT2iepCxP8Od\nZYiI+L3GtsgtkGytHWStHeqOgsr16gU33gh/+EPdX6PuFRFpitzRteKxM3AeeQSWLIF16+r2fI1c\nEZGmyB0t8i+MMWuNMVPdUVBlkZEwfboz3W1dhiOqRS4iTVFwI19/nrV2rzGmA/C5MSbTWrus/MEZ\nM2ZUPDE5OZnk5OR67+CWW5xJtT77DC65pObnKshFJNCkpKSQkpLSqG24ba4VY8x0IN9a+7Trdr3m\nWqnJ++/DzJnw/ffObImnY62l7Zy2ZP42k5jwGLfsW0TEm7w614oxJtQYE+G6HgZcDKQ2dHs1mTDB\nWYSitjnLjTEkxSSRmuuRMkRE/FJj+shjgGXGmHXAKuAja+1n7imrKmOc4YiPPFL7SUI64CkiTU2D\ng9xau91ae7brMsBaO9udhZ1s1CgYNAiee67m56mfXESaGr88s/N0Zs+GJ56AvLzTP0dBLiJNTUAF\neb9+Tn/57Bra/gnRCWTuz6SkrMR7hYmI+FBABTnAjBkwfz789FP1j4eHhNOpdSc2H9js1bpERHwl\n4IK8Y0e4/faaT91X94qINCUBF+QA990HS5c663tWRyNXRKQpCcggb90aHn4Y7r+/+scHxg5UkItI\nkxGQQQ7w//4fbNkCX3556mPqWhGRpiRggzwkBP70J2clobKyqo91i+xG3vE88gpqGKcoInKGCNgg\nB5g0yVka7u23q97fzDQjMTpRp+qLSJMQ0EFefur+Qw9B4UkrvKl7RUSaioAOcnDW90xIgBdeqHq/\nglxEmoqAD3KAxx93zvY8dOjEfQpyEWkqzoggHzAAxoxx5mEplxidSFpuGmW27PQvFBE5A5wRQQ7O\nwhP/93+we7dzu03LNrQPbc+2vG2+LUxExMPOmCDv3BluvdVZ47OculdEpCk4Y4IcnDM9lyyBtDTn\ntoJcRJqCMyrIIyPhwQfhgQec200pyI8fh5wcX1chIr7gtsWXT9mwGxdfro/CQoiPh7//HWISMhn7\n5li23LnF63V4wrFjsG2bMzXBjz86X8uv5+Y6Z7tec40zgqd9e19XKyIN0ZDFl4M9VYyvtGgB//M/\nzgyJ36zsxd78veQX5RMeEu7r0urk6FHYurX6sN6/H7p3h169oHdviE86ysgxOUTE5mLCczl+HL59\ndRz9+xsefdQ5ZhAU5OvvSEQ87YxrkYMz98q55zp95nMODeG5y59jeOfhPqmlOqWlsGMHpKc7l82b\nnbDe/GMZeccP0KlvLrE9c4nqnENodC7BbXKwrXLJJ4d9x3LJPZpLztEcymwZMWExxITHEB0Wzfa8\n7QzrNIzfdn2Ju34XzLFj8PzzMNx/vnURqUVDWuRnZJADfPEF3HYbjHryJkaeNZxbz7nV6zWUlDhd\nIeWBXX7ZtMnp+ugxMIv9idM5FLqGoyaHIyUHaNOyDdFh0USHRTsBHRpdEdTRYdHEhJ24Hh4SjjEn\nft/5RflMencSwc2CeetXb7P4nVCmTYPLLnNOmurQwes/AhGpJwX5SS69FMJ+OY+4hC08d/lzHttP\ncbHTHbJxY9XA3rwZ4uKgf/8Tl4QEOKvnMV5KfYpnVz3LbefcxqSEScSExdA+tD3Ng5o3rpbSYm5Z\ncgubD2xmyeQlhJS0Z8YMeP11Z2jmbbepu0XEnynIT7J+Pfzipq/o95sZfHPL127ZZnExfPMN/Pvf\nJ4J761bo1MkJ6cqhHR8PYWEnXmut5e2Nb3P/F/czrNMw5lw0h26R3dxSV2XWWh788kE+yPyApdcv\npWtkV9LS4Le/hcOHne6WkSPdvlsRcQMFeTWuvnEfH3brTcH0vCrdEPWRnQ2ffgoff+x02fTqBaNH\nQ2KiE9h9+0KrVjVvY03WGu5eejcFxQXMu3Qe/9H1PxpUS308++2zPLniST75z09IiknCWli40DkQ\nfPHFzpQG0dEeL0NE6qEhQY611iMXZ9O+t2OHtea/4+zqzTvr/JrSUmtXrbJ2+nRrhwyxNjLS2okT\nrX3lFWuzs+u3/6zDWfbXi39t456Ks/O/n29LSkvqt4FGWpi60HaY08H+a/u/Ku77+Wdr773X2vbt\nrf3zn60tLvZqSSJSA1d21itvz/gWOUD3P1xK35/v4NM/jz3tcw4dgs8+g08+gX/+E9q1cybiGjMG\nzjsPmtez67qguIC5K+fyzLfPMHXwVB46/yEiWkQ08jtpmK+2f8W1713LX8b8hYn9J1bcn54Od9wB\nBw443S2jRvmkPBGpROPIT2Pc0CTmP7+BjIyx9Ovn3GetE2Qff+yE9/ffO0E2ZoxzULB794bty1rL\nu+nvMu3zaZzT8RxWT11Nj6ge7vtmGuDC7hey9PqljF04lpz8HH479LeA0y305ZfOCkvXXgu//KWz\nUEdMjE/LFZF6ahIt8tc3vM5TH35El1VvcdttTnB//LET5uWt7l/8AkJDG7ef7/Z8x91L7+ZI4RHm\nXTqP5G7JbqnfXbbnbeeS1y9hUv9JzLpwVpVjBkeOwGOPwSuvwCOPOAdGg5vEx7yIf9HBztPYkLOB\na969lqAX06t0mfTv7ywX11jZ+dk89OVD/HPLP5mZPJObBt1EUDP/HOO37+g+xrw5hgHRA3hp7Eun\nDHfMyIA774S1a52TqoYOdS7nnusMpRQRz1KQn0ZRaRFtHm9D3v15tAxu6bbtHi85zjMrn+HplU9z\n06CbePj8h2nTso3btu8p+UX5XP3u1RhjeGfiO4SFhJ3ynNxcWLMGVq8+cQkNPRHsQ4fCOedA69Y+\n+AZEzmAK8hokvZDE38f/ncFxgxu9rTJbxuKMxdz3+X0MjB3Ikxc9Sa+2vdxQpfcUlxYzdclUMvdn\n8tF1H9E+tOZZtqx1zlKtHOzr1kG3blXDPTHRmbxLRBpGQV6D69+/ntE9RnPj2TfW+7VFpUV8t+c7\nlv20jGU/LWP5T8vpEdWDJy96kgu7X+j+Yr3EWstDXz7E4szFfHr9p/U+Oam42DkpqnK4b93qhHl5\nsA8b5kzw5S8KC+HVV53pE/TBI/5IQV6DOd/MITs/m7mXzK31uflF+Xy7+1uW7XSCe3XWanq36835\nZ53P+Wedz6izRhEXceZ0GP951Z+Z880cPr7uYwbGDmzUtvLznRFA5cG+fLlzwtQf/wjJye45JtEQ\nxcWwYIFzQHfAAKe/f/Vq57+MpKSq/1X07Om7OkUU5DX4dMunPLXiKb749RenPHbg2AGW/7ScZT8t\n4+udX7Nx30YGxQ5ygrvr+YzsMpLIlpE+qNp73tn4Dnd8cgfvTHrHraNtiovhzTdh1iyIjXUCffRo\n7wVlaalzNuuMGU430GOPwYgRJx4v/+BZterEh09+/okDvcOGOdd1Bqx4i4K8BnuO7GHgiwPJ/e9c\ndh/e7XST7FzG1z99ze7DuxneeXhFi3top6G0al7LOfdnoPITh56//HkmJUxy67ZLSpzx6rNmQVSU\nE+iXXOK5QC8rg/ffd/YTFeXs9xe/qNtrs7OdA73l4b5mjbP6VOVW++DBVefREXEXBXkNrLV0eLID\nYSFhFBQXcH7X8yuCe2DsQIKbadA0wLrsdYx5cwzXJFzDlIFTSIpJavAcNdUpLYX33nNaxqGhTtCO\nGeO+QLfWOUfgD39wZnmcNavxHxhlZc588eUt9lWrnHVhe/WCIUOcYwA9e0KPHs4lKso934s0TQry\nWqzavYo2LdvQt11ft4bTmWbXz7t4fs3zvJX2FqHNQ5k8YDLXDriW3u3cd9SyrAwWL4aZM53A/eMf\n4YoroFkDV5G11jlL9ZFHnFWWHnsMrrzScy3+wkLYsAG++845wLttm3PZutU5kao81Hv0qBryXbro\nRCupmYJc3KrMlvHt7m9ZmLqQd9PfpXPrzkweMJlrBlxD59ad3bOPMvjwQyfQS0udlvRVV9Uv0Jcv\ndwJ871549FG4+uqGfyA0lrXO3DXloV454LdtcxbI7tKl+pDv1w9auu80h4BjrXOG8cGDVS95eVVv\nl5TAddfBRRf57vfsSQpy8ZiSshJSdqSwMHUhizMXMyB6AJMHTGZi/4l0CGv80kPlXSIzZzqLTD/y\nCEyaVPMiGGvXOsGfkeHMj3PDDf7f2i0sdJb5Kw/48pDfsgUKCmD+fGd0T6ArLnbWmM3NhX37nK8H\nDtQc0Hl5zgdZ27bOJSrqxPXKl4IC+Otf4fhxZ9K3KVPOrBPTFOTiFYUlhSzdupSFaQv554//ZESX\nEVybcC0T+k2gdYvG/UVZC0uXOi3rvDwn0K+9tmpAp6Y6Ab52LTz8MNx885kxFvyjj5wVnCZMgNmz\nIdyP1gsvLXXCtnIw13T98GFnBtHoaGeJwQ4dnOUNqwvmysFd19+jtc5/Yv/7v84aAddd54R6fLxn\nfw7eoCAXrztadJQPN33IWxvfImVHCqN7jGbygMmM6T2mUSN/yvu8H33UGUXy8MPOMMBZs+Bf/3IW\n1r7tttoX9Ag0eXlw991OSPmydV5QAM8+C2+84XQH5eU5rd7o6BPhXNP1qCjvLSmYlQUvvggvv+yc\n4PW73zkH0AN1SUMFufhUXkEe72e8z8K0hazds5ZxfccxecBkRvcYTUhQw5rM1jrL6j36qDMlwLRp\nzh9qQ1urx4qP8fnWz9l/bD+tmreiVXArWga3rLhe3deWwS1pZrzbGeur1nlpqXPi1PTpzhj6++6D\nrl2d1nQgdFu9+67TSs/Nhdtvd/5ba9vW15XVj4Jc/EZ2fjbvbnyXtza+Rfq+dC7rdRkT4idwWe/L\nCA9pWCpZ27BRKPlF+Xy8+WMWZSxi6dalDOk4hK5tulJQUkBBcUGtXwtLC2kR1OKUcG8V3Io2Ldsw\nJG4II7uMZESXEUSHue/Mocqt87/9DS64wG2bPkX5MYoHHnBa03PmVD1xKtCsXg3PPQdLlsDEiU63\ny8DGnbRcRX6+s7h6ZuaJy5//7Jz01lgKcvFLe4/s5R+b/sHizMWs3LWSC7pdwIT4CYzrM84tB0qr\n8/Pxn1myeQmLMhbx1favGNllJBP7TeTK+CtrnSDsZGW2jMKSwmqD/mDBQVZnrWbFrhV8u/tb2oe2\nZ2SXkU6v2R5uAAALeUlEQVSwdx7BgOgBjZ7SeMkS+M1vnNb544+7/0SkVauc/3T27XO2P27cmTNF\nQU6O0+Xy4ovOyKDf/Q7Gj6/bil/Wwp49VcO6/HLggHP+QHz8icuYMe456KogF7936PghPvnxExZn\nLuazrZ8xKHYQ4+PHMyF+Al0juzZq2wcLDvKPzH+wKGMRX+/8muRuyUzsP5FxfcYR1crzZ+mU2TIy\n9mWwYtcKVuxewYpdK8jOz2Zop6GM7Oy02Id3Ht6g6R480Tr/8Ud46CFYudKZwuDGG/2/+6Shiovh\ngw+cVvrWrU631a23Ov35x487o4YqB/WmTc7XsLCqYR0f78wddNZZnuuDV5BLQCkoLuCLbV+wOHMx\nSzYvoUvrLkyIn8CEfhNI6JBQp5O2co/m8kHmB7yX/h6rslYxusdoJvabyJg+Yxo9gsYd9h/bz7e7\nv3XCfdcK1u5ZS7fIbhUt9pFdRtKnXZ86n6DmjtZ5To4zzPPtt+H3v3c+IBq7OlZNjhUfY8+RPRSX\nFhMSFEJIUAgtgltUXA8JCiHIBHntJL31651Af+89p/88K8tZ2vHksO7b1zdn6Xo1yI0xlwLzgCDg\nr9baJ056XEEudVZSVsI3P33D4szFLM5cTEhQiBPq8RMY1nlYlYONe47sYXHGYt7LeI8f9v7Apb0u\nZWL/iVzW67JqF8nwJ8WlxWzI2VCl1X606CjDOw9neOfhDO00lCEdh9C21emP0OXlwV13wTff1K91\nnp8PTz/t9OXecIMztLN9/XqZTvlesvOz2XNkD3uO7CHrSFa114+XHCcuPI4WwS0oKi2quBSWFFZc\nL7NlVYK9ukt5+Ic2D6Vvu74kRieSGJNIQoeEBv3e8/Kcg6I9etR/cXVP8lqQG2OCgE3AaCALWANM\nttZmVHqOXwZ5SkoKyX52xoVqqspayw/ZP7A4wwn1gwUHubLvldjtlrSwNNL3pTOmzxgm9pvIxT0v\n9ukEZ+74OWUdzmLFrhWszlrN6j2r+X7v98SExXBup3M5t6NzGRw3+JSwWrLE6SK46qpTW+eV6you\ndk6gmTnTmThs1iwnvGpyvOQ42/K2sePQjhPhfDiLPfmur0f2cLDgIB3COtApohMdIzrSMaJj1eut\nnetRLaMwxtT4syotK6W4rLhK0J/ucrjwMBn7MkjNTSUtN43M/ZnERcQ5we4K9wHRA+jTrk+tcyj5\n499eQ4K8oT1iQ4Et1todrh2/BVwJZNT0In/gj7841VSVMYbBcYMZHDeYxy58jB8P/MjizMW88+Y7\nzHx0Jr/s/ktaBLfwSW0nc8fPqVPrTkxKmFQx42RpWSmZ+zNZs2cNa7LW8FbaW6TlptGrbS8n2F0B\nf8nliaSmhnD33c6c6pVb5ykpKVxwQTLvv+/0g3fp4gxpPOecE/s9dPwQWw9uZWveVrYc3FJxfWve\nVvYd3UfXyK50j+xeEc5nx57NmNZjKoI6JiymXgdya/pZBTULIqhZUJ2XYhzbZ2zF9ZKyErYc3EJq\njhPsb6W9RWpuKlmHs+jTro8T7B0GkBjjBH3n1p0runHq8/uz1lJYWsjRoqMcLT7K0aKj5BflV1xP\n7pbss/8IGxrknYBdlW7vBoY1vhyRU/Vu15tp503j2OfHuLz35b4ux+OCmgWREJ1AQnRCxYpWhSWF\npOamsjprNauyVvHc6ufYfmg7idGJnHvtuVxx4blMuv1crvllXx6f3YydO2HESMsRu5dbZ22lba+t\nfJC3lacXuUI7bytFpUX0jOpJz7Y96RXVi2Gdh3Fd4nX0bNuTLq27+O0C4icLbhZMfPt44tvHV5l+\n+VjxMdL3pZOak0pqbipffvslqbmpFBQXMCB6AInRiaRvT+fI0iNOGFcTzid/DWoWRFjzMMJCwqp8\nDQ8JZ2DswIALcv/rMxE5g7UIbsGQjkMY0nFIxX35Rfl8v/d71mStYc2xTwi75VFeytvPi79PpCx9\nM8FjnqRNqzAWHe5Fzx096RnVk8t6XUavtr3o2bYnHUI7nNGzgIY2Dz3lZwbOAei03DRSc1LJMBnE\nRcSdEsonB3X51+ZBftSZXklD+8iHAzOstZe6bj8IlFU+4GmMUdiLiDSAtw52BuMc7PwlsAdYzUkH\nO0VExDsa1LVirS0xxtwBLMUZfjhfIS4i4hseOyFIRES8w+1Tuhljuhhj/mWM2WiMSTPG3OnufTSU\nMSbIGPODMWaJr2sBMMZEGmPeM8ZkGGPSXccefM4Y86Dr95dqjHnTGOP1sX7GmL8ZY3KMMamV7mtr\njPncGLPZGPOZMab+57q7v6YnXb+/9caY940xbXxdU6XH7jXGlBljvDr/3+lqMsb8zvWzSjPGPHG6\n13uzLmPMUGPMalcurDHGnOvlmqrNy/q+1z0xN2cxcI+1NgEYDvzWGNPPA/tpiLuAdPxn1M2zwCfW\n2n5AEn4wDt8Y0w2YCgy21ibidJ1d64NSXgEuPem+B4DPrbV9gC9dt31d02dAgrV2ILAZeNAPasIY\n0wW4CNjp5XqgmpqMMb8ArgCSrLUDgKf8oS5gDvAHa+0g4I+u2950urys13vd7UFurc221q5zXc/H\nCaeO7t5PfRljOgOXA38FfD7mytVyO99a+zdwjjtYa3/2cVkAh3HeXKGug9qhOGfvepW1dhmQd9Ld\nVwALXNcXAON9XZO19nNrbZnr5irAPYuZNqIml7nANG/WUu40Nf0GmG2tLXY9Z5+f1LUXKP8vKhIv\nv9dPk5edqOd73aOz5btad4Nw3uC+9gxwH1BW2xO9pDuwzxjzijHme2PMy8YYD05dVDfW2oPA08BP\nOCOSDllrv/BtVRVirLU5rus5QIwvi6nGTcAnvi7CGHMlsNtau8HXtVTSG/gPY8y3xpgUY8yQWl/h\nHQ8ATxtjfgKexPv/UVU4KS/r9V73WJAbY8KB94C7XJ80PmOMGQvkWmt/wA9a4y7BwGDgL9bawcBR\nvN9VcApjTE/gbqAbzn9S4caY//RpUdVwTeTjL11kGGMeBoqstW/6uI5Q4CFgeuW7fVROZcFAlLV2\nOE6D6h0f11NuPnCntfYs4B7gb74owpWXi3Dy8kjlx+ryXvdIkBtjmruKet1a+4En9lFPI4ErjDHb\ngYXAhcaYV31c026cVtMa1+33cILd14YAK6y1B6y1JcD7OD8/f5BjjIkFMMbEAbk+rgcAY8yNON12\n/vCB1xPnQ3i96/3eGfjOGOO+pYsaZjfOewnXe77MGNPOtyUBMNRau9h1/T2ceaS8qlJevlYpL+v1\nXvfEqBWD8ymXbq2d5+7tN4S19iFrbRdrbXecA3dfWWt/7eOasoFdxpg+rrtGAxt9WFK5TGC4MaaV\n63c5GucAsT/4EJjiuj4F8HkjwTWd833Aldba476ux1qbaq2NsdZ2d73fd+McuPb1h94HwIUArvd8\niLX2gG9LAmCLMaZ8IuALcQ5Ye00NeVm/97q11q0XYBROP/Q64AfX5VJ376cR9V0AfOjrOly1DMSZ\nAng9Tmulja9rctU1DedDJRXnQEtzH9SwEKePvghngrb/AtoCX+D8sX0GRPq4ppuAH3FGhpS/1//i\no5oKy39OJz2+DWjr65qA5sBrrvfUd0Cyn7ynhuD0Sa8DVgKDvFxTtXlZ3/e6TggSEQlwHh21IiIi\nnqcgFxEJcApyEZEApyAXEQlwCnIRkQCnIBcRCXAKcmkyjDHdqpvuVSTQKchFRAKcglyaJGNMD9es\nk+f4uhaRxmrQmp0igcwY0xfndO0p1lp1tUjAU5BLUxONMwHRBGttpq+LEXEHda1IU3MIZ5Kr831d\niIi7qEUuTU0RcBWw1BiTb61d6OuCRBpLQS5NjbXWHnOtGvW5MeaItfYjXxcl0hiaxlZEJMCpj1xE\nJMApyEVEApyCXEQkwCnIRUQCnIJcRCTAKchFRAKcglxEJMApyEVEAtz/B5ogu2adFjDlAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11206a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sad = []\n",
    "sse = []\n",
    "numKs = 20\n",
    "\n",
    "for k in range(2,numKs):\n",
    "    recon = shape(findCode(v,k)) * gain(v)\n",
    "    print(recon)\n",
    "    sad.append(sum(abs(recon - v)))\n",
    "    sse.append(sum((recon - v)**2))\n",
    "\n",
    "plt.plot(range(2,numKs), sad, label='SAD')\n",
    "plt.plot(range(2,numKs), sse, label='SSE')\n",
    "plt.xlabel(\"k\")\n",
    "legend = plt.legend(loc='upper center', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at **k**=14 the error is zero. This is because the sum of **v** is 14. In other words, when **k**=14, **v** is in the codebook.\n",
    "\n",
    "#Conclusion\n",
    "So there you have it, as promised we \"_perceptually vector quantized_\" something. As we have seen, vector quantization involves finding (or computing) a codeword for a given vector. Perceptual vector quantization uses a codebook made up of all the codewords where the sum of the absolute values of their elements is **k**. You get to pick and chose **k**, a low value of **k** will result in a small codebook and little precision. Increasing the value of **k** improves the precision (up to a certain point).\n",
    "\n",
    "**Let me know what you want to see in part 2 (Twitter @LT_Pragmatic).**\n",
    "\n",
    "# Further reading\n",
    "This work is based on:\n",
    " * The [Perceptual Vector Quantization demo](https://people.xiph.org/~jm/daala/pvq_demo/)\n",
    " * The paper [Perceptual Vector Quantization for Video Coding](http://jmvalin.ca/papers/spie_pvq.pdf) by Jean-Marc Valin and Timothy B. Terriberry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
